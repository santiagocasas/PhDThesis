\chapter*{Conclusions \label{Conclu}} % Main chapter title

\addcontentsline{toc}{chapter}{Conclusions}
 % For referencing the chapter elsewhere, use \ref{Chapter1} 


%\todos
%----------------------------------------------------------------------------------------


%----------------------------------------------------------------------------------------

\done\todo{finish conclusions}
In this thesis we have investigated non-linear structure formation in models of Dark Energy and Modified 
Gravity which go beyond the standard $\lcdm$ scenario. We have focused on predicting its impact
on parameter constraints and contrasting the difference of the linear and the non-linear calculations on observable properties like Weak Lensing, 
Galaxy Clustering and the evolution of background quantities.

\subsection*{Dark Energy and Modified Gravity}

In \cref{chap:DE-MG-Overview} we introduced the theoretical framework of cosmology, which is
based on Einstein's General Relativity (GR) and then we proceeded to explain the concordance $\lcdm$
model and its main properties. 
We have argued that despite the actual data being well explained by the standard model, 
there are some unsatisfactory properties with the Cosmological Constant, namely the so-called fine-tuning
and coincidence problems, that motivate the extension of General Relativity by an extra dynamical degree of freedom.
We have focused on theories of Dark Energy (DE) and Modified Gravity (MG) in which this extra degree of freedom  is represented by a dynamical scalar field. The scalar field can not 
only modify the background cosmological solutions,
but in some cases it can also lead to the appearance of an extra "fifth-force" acting between test bodies.
In the second half of \cref{chap:DE-MG-Overview} we have classified the DE and MG models into universally coupled  and non-universally coupled. The former are those models in which all matter and radiation species couple
in the same way to the scalar field, while the latter are models in which just a specific matter component feels the influence of the field. 

General Relativity has been thoroughly tested at laboratory and Solar System scales. It has been found that the
coupling to standard matter (baryons) is very well constrained to be negligibly small.
Therefore, universally coupled models have to invoke a "screening" mechanism that recovers GR at small scales (see \cref{sec:universal-coupling}).
On the other hand, non-universally coupled theories pass the stringent solar system constraints by decoupling the baryons
and allowing only for dark sector interactions, involving the scalar field and dark matter or neutrinos, as we discuss in \cref{sec:nonuniversal-coupling}.

For universally coupled theories, we focus on Effective Field Theory (EFT) models, Horndeski models and on parameterized Modified Gravity, which
are very general descriptions of theories of GR plus a scalar field.
EFT includes in the action all possible terms allowed by symmetries at first order in perturbation theory, while Horndeski is the most general theory
of GR plus a scalar field, which is second order in the equations of motion and free of ghost instabilities.
Both theories can be mapped to each other at the linear order, by using the so-called $\alpha$-functions.
We explained this more in detail in \cref{sub:EFT-of-DE}.
If we want to study general modifications of gravity affecting the gravitational potentials $\Psi$ and $\Phi$, but we do not want to focus on a particular Lagrangian description, we can parameterize the deviations of GR in terms of two
general functions of scale and time, namely $\mu(k,a)$ and $\eta(k,a)$. As we explain in \cref{sub:parameterizing-MG}, $\mu$ expresses the deviations of the relativistic Poisson equation, while $\eta$
expresses the gravitational anisotropic stress (also known as gravitational slip), which is the ratio $\Phi/\Psi$.
Both functions reduce to unity in the standard GR case or if the DE model just modifies the background equations.

For non-universally coupled theories, we focused on two distinct scenarios. The first one called Coupled Dark Energy
(CDE) is a model in which there is a dark sector interaction between Dark Matter and the Dark Energy field, see \cref{sub:CDE}. This leads to a fifth-force that modifies the growth and the clustering of DM particles and introduces a gravitational bias.
We studied this model in the non-linear regime, based on cosmological N-body simulations and we found
noticeable differences in the non-linear matter power spectrum depending on the strength of the DM-DE coupling. This was a subject of \cref{chap:Fitting-CDE}.
The second non-universally coupled model we study is Growing Neutrino Quintessence (GNQ) in which
the mass of the neutrinos is directly coupled to the scalar field (referred to as ``cosmon``).
In this model Dark Matter and baryons follow standard gravity, but neutrinos feel an extra force among them, which
is very strong (of the order of $10^2$ times the gravitational force) and leads to the formation of large neutrino lumps. Depending on the parameters of the model, these lumps are stable and grow with time
or they present very rapid oscillations, dissolving and forming again. To study the dynamics of these lumps
and their backreaction effect on background quantities, we perform specialized N-body simulations, as we 
detail in \cref{chap:GNQ}. 

\subsection*{Statistics and the Fisher Matrix formalism}

In order to study the impact of non-linearities onto the determination of cosmological parameters,
we need to make use of Bayesian statistical tools, which we review in \cref{chap:Statistics}. 
In the first part we introduce the concepts of Gaussianity, linearity and statistical homogeneity and 
we conclude that they are intrinsically connected and that therefore non-linear structure formation
introduces non-Gaussianities and non-homogeneities into our statistical analysis.
Using Bayes' theorem we can define the likelihood as the probability of obtaining a particular model given the data, therefore
we can find which are the set of model parameters that maximize the likelihood function.
We then developed the concept of Fisher Matrix, which is a way of approximating the likelihood function at the maximum, 
assuming that around the peak, the likelihood can be approximated as a Gaussian (see \cref{sec:Fisher-Matrix-forecasts}).
Since the Fisher matrix for the model parameters can be obtained without data, just by knowing the data and noise covariance matrices,
we are able to forecast the result of future experiments in a theoretical way.

In this work we have dealt with the predictions for future galaxy surveys: Euclid, SKA1, SKA2 and DESI (for more details see \cref{sub:FutureSurveys}).
These missions will observe approximately $10^7 \sim 10^9$ galaxy shapes and positions (angles with spectroscopic plus photometric redshifts) at redshifts of $z \approx 0-3$, giving us valuable information
in the linear as well as in the non-linear regime of structure formation.
With the galaxy positions and spectroscopic redshifts one can measure what we call Galaxy Clustering (GC). This is 
a combination of the shape of the power spectrum (the Fourier transform of the galaxy two-point correlation function), 
its amplitude as a function of time and its particular features like Baryon Acoustic Oscillations and Redshift Space Distortions.
What we call Weak Lensing (WL) is the process of using galaxy shapes and photometric redshifts one obtains the cosmic shear power spectrum, which
can be related to the matter power spectrum integrated along the line of sight. This provides us with valuable information about the evolution
of structures in the Universe.
In \cref{sec:FisherTools-code} we explain the implementation of a Fisher Matrix code for GC and WL, which contains different methods 
to forecast the errors on cosmological parameters obtained by future surveys. This code, called \textsc{FisherTools}, integrates
very well with other commonly used codes in the community, like Boltzmann codes or emulator codes and has been thoroughly 
tested within the Inter Science Taskforce and the Theory Working Group of the Euclid collaboration.


\subsection*{Linear and non-linear forecasts for Modified Gravity with future surveys}

In \cref{chap:MG-forecasts} we have used the \textsc{FisherTools} code to 
forecast the sensitivity of future surveys to general modifications of gravity given by $\mu$ (the deviation from the GR Poisson equation) 
and $\eta$ (the anisotropic stress) in the linear and in the 
mildly non-linear regime of structure formation. 
For the linear power spectrum we use a modified Boltzmann code called \textsc{MGCAMB} \mcite{MGCAMB} which is able to compute the linearized
Einstein-Boltzmann equations for modified gravity. For the non-linear corrections we test two prescriptions: one based on a rough application
of the \textsc{Halofit} \mcite{Halofit} formalism on top of the linear spectra and a prescription in which we interpolate
from an MG non-linear power spectrum to a GR non-linear spectrum at small scales, to emulate a screening mechanism. This is the 
so-called "Hu-Sawicki" (HS) prescription \mcite{Hu Sawicki}. In section \cref{sub:MG-nonlinear-spectra} we give more details about our implementation.

In this project, we have tested three different parameterizations of Modified Gravity.
In two of them $\mu(a)$ and $\eta(a)$  are smooth functions of the scale
factor $a$ and we have neglected possible scale dependence. In the third one, we have not assumed any specific functional form for $\mu(a)$ and $\eta(a)$,
but we have binned these functions in 5 redshift bins and we have assumed that $\mu(z_i)$ and $\eta(z_i)$ 
are free parameters at each redshift bin $z_i$.
To obtain the fiducial parameters for these three cases, we have computed the best fit parameters obtained by
performing a Markov-Chain-Monte-Carlo calculation, that computes the likelihood function obtained with recent data from the \textit{Planck} CMB satellite.

In the redshift-binned scenario, we find that the $\mu(z_i)$ and $\eta(z_i)$ are quite correlated among each other and
with the primordial amplitude of the power spectrum $\mathcal{A}_s$. We find that including non-linear power spectra and adding
a \textit{Planck} covariance matrix as prior, reduces the correlations considerably. Particularly, in the non-linear case, the correlation
with the primordial amplitude disappears almost completely. We find that the lower redshift bins are the best constrained
by observations. 
Using non-linear power spectra and Galaxy Clustering only,
the parameters in the first bin $z_1$, covering from $z=0$ to $z=0.5$, are constrained for $\mu$ at the 
7\% level and for $\eta$ at the 20\% level; combining GC with Weak Lensing improves the constraints 
to 2.2\% and 3.6\%, respectively. If one considers only linear scales in the analysis,
the GC+WL combined errors on $mu_1$ and $\eta_1$ are twice as large, while the individual GC
and WL lensing errors are 10 to 20 times larger.
This shows the importance of having a proper model of the non-linear power spectrum if one wishes to extract information
on the Modified Gravity parameters with future surveys.

We further apply a Zero-phase Component Analysis (ZCA) decorrelation, which in analogy to the commonly used
Principal Component Analysis (PCA) gives us a set of decorrelated variables, in which the new covariance matrix is diagonal.
With these new set of variables, we can find which are the combinations of MG parameters that can be best constrained with future surveys.
We find that for low redshifts, the best constrained parameters are the combination $2\mu + \eta$, which will be measured at a precision of better
than 1\%, if one combines GC+WL and \textit{Planck} priors. The best constraints on the decorrelated parameters are 2 orders of magnitude better
for the linear case and 1 order of magnitude better for the non-linear case, compared to the original parameters.

For the case in which we parameterize $\mu(a)$ and $\eta(a)$ with smooth functions of time, we consider two possible behaviors. The first one, is the so-called
late-time parameterization in which the modifications of gravity are stronger at late times and are proportional to the fraction of Dark Energy
$\Omega_{DE}$ in the Universe. The second one is the so-called early-time parameterization, which consists of the zeroth and first terms of a Taylor expansion
of a general function of $a$, around $a=1$. In this parameterization, the modifications with respect to GR can be large at high redshifts.
In both cases we find that using non-linearities and combining GC plus WL, we can constrain the modification to the Poisson equation $\mu$
and the modification to the lensing potential $\Sigma=(1+\eta)\mu/2$ at around the 1\% level, while if we use only linear
scales, the constraints are of the order of 7\% and 2\%, respectively.
An interesting difference between these two parameterizations is that in the late-time parameterization, Galaxy Clustering is only able
to constrain the $\mu$ function, while WL is able to constrain $\Sigma$, which is what one expects naively from
the subhorizon perturbation equations. Nevertheless, in the early-time parameterization since $\eta$ and $\mu$ are not unity at high redshifts,
the terms proportional to derivatives of the gravitational potential, $\dot \Phi $ and $\ddot \Phi$, appearing in the evolution equation
for the density perturbations (\cref{eq:dotdotdelta-mueta}), are not negligible. Therefore, one can observe the effects of $\eta$ both with the clustering of galaxies 
and with cosmic shear.

We also tested the effect of our non-linear prescription onto the forecasted constraints in two different ways. The non-linear HS
prescription depends on two parameters $c_{nl}$ and $s$, which determine how fast and at which scales the MG power spectrum
goes back to the GR case. In principle these parameters have to be adjusted by comparing with N-body simulations. First we tested how much the constraints 
on $\mu$, $\eta$ and $\Sigma$ changed when  modifying the fiducial of $c_{nl}$ and $s$. We find that for the most extreme variations
of the HS parameters, the 1$\sigma$ error on $\mu$ gets affected by a factor $\sigma_{\mu} \times (1\pm^{0.9}_{0.3})$, while the constraints on $\Sigma$ vary around $\pm 6\%$
(see \cref{fig:Density-GC-HSpars} and \cref{fig:Density-WL-HSpars}).
The second test performed, was the inclusion of the HS parameters as nuisance parameters on the forecast. 
We found that after marginalizing over these nuisance parameters, the results on all cosmological parameters are quite robust and the constraints are just slightly worse, as was expected by the addition
of two extra parameters.
All the above mentioned constraints refer to the Euclid probe, but we also performed the same forecasts for SKA2, SKA1 and DESI-ELG (which measures GC only). These tables can be found in \cref{chap:MG-forecasts}.
In order to compare across experiments and across different cases (linear, non-linear, with and without prior) we defined the Figure of Merit (FoM, \cref{eq:FoM})
and the Figure of Correlation (FoC, \cref{eq:FoC}), which are good measures of the constraining power of an experiment and the correlation among the parameters.

 
\subsection*{Fitting and forecasting Coupled Dark Energy in the non-linear regime}


For the Coupled Dark Energy model, which is a quintessence model in which Dark Matter particles and the scalar field interchange
energy and momentum, we used the publicly available \textsc{CoDECS} N-body simulations \mcite{Codecs Baldi} 
to find a fit to the non-linear power spectrum and
applied them to improve previous forecasts on this model for future galaxy redshift surveys, which had been done taking
into account linear scales only \mcite{cite Luca, Valeria}.

The fitting formulae we found are functions of the DM-DE coupling $\beta$ and the redshift $z$, and are very precise when compared to the  full simulations.
However, since they were calculated as the correction with respect to the $\lcdm$ case, 
we still need to add on top of them a semi-analytic or numeric prescription for the non-linear power spectrum, which
can be varied with respect to the standard cosmological parameters.
Here we used the Halofit formula and the Coyote Cosmic Emulator as the ``fiducial`` $\lcdm$ non-linear power spectrum. 
We found that the \textsc{CoDECS} $\lcdm$ simulation departs from Halofit at around 5\% 
at scales $k \lesssim 0.2 \mathrm{h/Mpc}$ and as much as 15\% at scales of about $k \approx 1.0 \mathrm{h/Mpc}$, for $z=0$.
The Cosmic Emulator performs somehow better, matching the $\lcdm$ simulations at present time ($z=0$) at better than 5\%
for all scales of interest $k \lesssim 2.0 \mathrm{h/Mpc}$, see \cref{fig:Error-comp-Halofit-CosmicEmu}. 
For this reason, we used the Cosmic Emulator as the baseline $\lcdm$ non-linear spectrum.
We included the error on the fitting functions, the error with respect to the Cosmic Emulator and the sample variance error
of the simulation as a source of error $\sigma_p(k,z)$ into our analysis, see \cref{fig:Error-sources}.

We computed the systematic bias on the parameter constraints (cf. \cref{sub:syst-bias-theory}) and 
found that the systematic errors due to the ignorance on the correct non-linear matter power spectrum can be as large as the statistical errors
(see \cref{tab:systbias}),
so that for data analysis it is extremely important to have the correct matter power spectrum under control.

We found that the including non-linear scales from a fit to simulations, improves the previous constraints (which used only linear spectra) on the coupling parameter $\beta^2$ 
by more than an order of magnitude. 
We investigated how the constraints change as a function of the maximum wavenumber $k_{max}$ included in the GC and WL analysis.
It is shown in \cref{fig:Contour-scale} and \cref{fig:WL-lmax-variation} that the errors decrease steadily with increasing $k_{max}$,
but then after $k_{max} \gtrsim 1$ the errors remain more or less constant.
We also show that using the wrong non-linear prescription, namely applying Halofit directly on top of the CDE linear spectra,
gives worse constraints and wrong degeneracy directions of the confidence contours. This is expected, since Halofit cannot account for the 
changes in structure formation at non-linear scales given by the "fifth-force".
Therefore, we show in this work, that to obtain the correct constraints on a modified gravity parameter, like the DM-DE coupling, 
it is necessary to calculate the correct non-linear power spectrum within the MG model.

The final constraint we obtain on $\beta^2$, which is $\sigma_{\beta^2} \approx 8\times 10^{-5}$ (see \cite{casas_fitting_2015})
is not far from the current
best limits reached with Solar System observations on a coupling to
baryons \cite{Agashe:2014kda}, which can be translated in our notation
as $\beta^{2}\le2\cdot10^{-5}$ at 1-$\sigma$.
Hence, we can expect that with future galaxy surveys and a correct modeling of the non-linear power spectrum and its associated
systematic errors, the dark sector couplings will be constrained with the same level of precision as we constrain the visible sector
within the Solar System nowadays.

\subsection*{Resummation methods for Horndeski theory}

As we have discussed in previous chapters, the estimation of the correct non-linear power spectrum when studying a Modified Gravity model
is of uttermost importance. We can use approximated non-linear prescriptions based on the Halo model as we did in \cref{chap:MG-forecasts}
to improve considerably the constraints obtained using just linear theory,
but we showed in \cref{chap:Fitting-CDE} that using the wrong prescription can bias our results and that the more precise approach is to 
find fitting functions directly from N-body simulations computed specifically for the model in question.
However, this is prohibitively expensive, we cannot calculate for each DE and MG model a set of N-body simulations covering
the parameter space. Therefore, while N-body simulations of Dark Energy and Modified Gravity provide 
the best estimates of the non-linear power spectrum, we cannot use them realistically for a large number of forecasts or future data analysis.

In \cref{chap:nonlinear} we took a different approach. The idea here was to use a recently developed resummation
formalism in cosmological perturbation theory, called eikonal Renormalized Perturbation Theory (eRPT), to calculate 
the non-linear corrections to the matter power spectrum at mildly non-linear scales, for a set of Horndeski models.
Since these calculations are relatively complex, we focus on Horndeski theory in the quasistatic limit,
in which the modifications to the gravitational potentials, which are given by $\mu$ and $\eta$, depend on 5 functions
of time, while the scale dependence is fixed, see \cref{eq:mufunc} and \cref{eq:etaFunc}.

Standard Perturbation Theory (SPT) in Large Scale Structure (LSS) suffers from the problem that corrections at higher orders (higher loops),
are not smaller the more loops one includes in the calculations. Therefore, one has in principle to sum contributions at all orders.
Being a resummation method, eRPT does not suffer from this problem, and we can compute the linear part plus 1-loop terms under certain conditions, ensuring that
higher orders will not spoil completely the result.
In this method we can derive an evolution equation for the non-linear power spectrum (see \cref{eq:evolution-eqn-Chi-eta}) which
depends on the linear power spectrum and the linear propagator (the solution of the differential equation for the growth).
This method has been compared to N-body simulations for $\lcdm$ by \mcite{Pietroni} and has been found to be 1--3\% accurate at mildly non-linear 
scales $k \lesssim 0.4 \mathrm{h/Mpc}$ for redshifts up to $z=0$.

In this project (which corresponds to a publication in preparation) we have computed the necessary terms for the evolution equation
for Horndeski models in the quasistatic limit. 
We have made several approximations on the way, which we specify in \cref{sec:The-Evolution-Equation} and we relax them progressively, to 
obtain a more realistic result.

Our preliminary results show that modifications of $\mu$ of around 15\% at small scales, compared to the GR case ($\mu=1$)
can affect the power spectrum at around 5\% at mildly non-linear scales (see \cref{fig:change-PS-resummed-YB1}).
As we have shown in previous chapters, such an effect would be observable by future galaxy surveys.
Since in these models the growth of perturbations is scale-dependent,
the correct calculation of non-linearities can also affect the constraints coming from data on $f\sigma_8$,
as we show in \cref{fig:change-fsigma8-Y}.

This eRPT method for Horndeski models still has to be tested against recently developed N-body simulations for Modified Gravity and we have to
study more in detail the effect of the approximations we have taken.


\subsection*{Dynamics of lumps in Growing Neutrino Quintessence}

In \cref{chap:GNQ} we studied a model in which the neutrino mass is coupled to the scalar ``cosmon`` field.
This model can be motivated by considering the ``cosmon`` field as a Goldstone mode coming from the breaking
of scale invariance and by considering the neutrino mass generation in the seesaw mechanism (see \cite{wetterich_growing_2007}).

The coupling between neutrinos and the scalar field $\beta(\phi)$ needs to be very high in order to respect constraints on early Dark Energy and
on the evolution of the equation of state. This strong coupling leads to the formation of large neutrino structures known as ``neutrino lumps``, 
which have been observed using specialized non-Newtonian N-body simulations as in \cite{ayaita_structure_2012}.
Previous studies had found that for a constant coupling $\beta$, there is no way of obtaining a realistic cosmology (see \cite{fuhrer_backreaction_2015}),
due to the strong backreaction effects caused by the large and stable lumps.

In the publication by \citet{casas_dynamics_2016} we studied, using N-body simulations, the dynamics of neutrino lumps 
for different masses of the neutrino at present time, $m_{\nu,0}$.
We found that there are two regimes: for large masses, above $m_{\nu,0} \gtrsim 0.5 eV$, the neutrino lumps become 
stable and grow increasingly with time, forming larger and larger structures; for 
small masses (below $m_{\nu,0} \lesssim 0.5 eV$) the neutrino lumps form and dissolve in time,
causing oscillations in the neutrino equation of state and in smaller measure also in the energy fraction of Dark Energy, and the total equation 
of state of $w_{\phi+\nu}$ due to the strong coupling (see \cref{fig:bckg-mod2-1} and \cref{fig:backg-wnu-wqnu-mod2}).
This mass-divide of the phenomenology of lumps can be visualized clearly in \cref{fig:Snapshots-of-models-oscill}.

In the case of stable and growing lumps, the backreaction is strong and we cannot obtain any realistic cosmological evolution. 
For very high neutrino masses our N-body code is not able to resolve anymore the highly non-linear equations. In these
extreme cases all neutrinos cluster into one single structure in the simulation box.

In the case of oscillating lumps, we find an interesting phenomenology. Neutrinos start as relativistic particles in the early Universe,
but then due to the ``cosmon`` coupling and the expanding Universe, their masses increase and they become non-relativistic.
This leads to an effective potential with a minimum, that stops the cosmon from rolling down its exponential potential,
giving rise to the onset of Dark Energy domination. This minimum causes oscillations in the perturbations of the scalar field,
which in turn causes oscillations in the perturbations of the neutrino energy density.
When neutrinos are non-relativistic, they tend to attract each other and form large  structures, however their acceleration towards the lumps
and the oscillations of the cosmon field, turn them again into relativistic particles, which can escape from the newly formed structures.
'
Despite this complicated non-linear interaction between the cosmon and the neutrinos, we find in this regime of small masses,
a cosmology compatible with present observations. The total Dark Energy equation of state $w_{\phi+\nu}$ is very close to $-1$
and the energy fractions of DE, DM and neutrinos, are compatible with recent observations by the \textit{Planck} satellite \cite{Planck:2015xua}
and by lower limits on the neutrino mass given by laboratory experiments \mcite{neutrino mass lab}. We also find that
the total gravitational potentials in the small $m_{\nu,0}$ mass regime are not significantly affected by the neutrino lumps.
The neutrino contribution to the gravitational potential $\Phi$ is two to three orders of magnitude smaller than the one coming from
Cold Dark Matter particles. Therefore, present constraints on modified gravity coming from the Integrated Sachs-Wolfe effect \mcite{Gianantonnio}, 
can still be respected.

Furthermore, we found a very interesting effect on the neutrino fluid. The acceleration and deceleration towards the neutrino lumps,
causes a net increase in the neutrinos kinetic energy, which translates into a shift of the mean of their momentum distribution. 
Since the neutrino distribution can be well fitted by a Fermi-Dirac distribution, this amounts to an increasing of the neutrino temperature.
This effect can be well visualized in \cref{fig:histogram-FermiD-1}. It could have interesting implications for observations in the
far future which plan to put constraints on the Cosmic Neutrino Background \mcite{some CnuB paper?}.

This is a good example of a Dark Energy model that cannot be solved using linear theory. The Klein-Gordon equation
for the scalar field (\cref{eq:klein-gordon-equation}) is highly non-linear and the rapid growth of $\delta_{\nu}$ cannot be approximated by linear perturbations. Present Boltzmann codes that are able to solve the GNQ model, start failing already at redshifts of about $z\approx 10$, since they cannot follow
anymore the oscillations of the neutrino equation of state and the large non-homogeneous values of $\delta_{\nu}$.
A previous N-body simulation trying to solve this model (see \cite{baldi_oscillating_2011}), based on Newtonian codes, was also 
not capable of evolving the neutrino evolution until present time. Therefore in this project we used an N-body code created 
in our research group \cite{ayaita_nonlinear_2016}, which includes both gravitational potentials $\Phi$ and $\Psi$,
allows for the possibility of having relativistic velocities, takes into account backreaction effects
and solves for the ``cosmon`` field $\phi$ on a grid, using a multigrid Newton-Gauß-Seidel solver.
All these effects come at the cost of a computationally demanding implementation, which is very difficult to parallelize in an optimal way.


\section*{Summary and Outlook}

In this thesis we have shown how important it is for future cosmological observations to take into account
the effects of non-linear structure formation. This is especially the case if one wishes to discriminate
between competing cosmological models in Dark Energy and Modified Gravity, which resemble 
very closely the evolution of the standard $\lcdm$ scenario at the background level,
but offer quite distinctive features at the level of large scale structure formation.

We have tackled this issue from different angles: 
semi-analytic prescriptions based on the Halo model (\cref{chap:MG-forecasts}), 
fitting formulae based on simulations (\cref{chap:Fitting-CDE}), 
resummation methods for higher-order cosmological perturbation theory (\cref{chap:nonlinear}) and directly computing,
computationally demanding, non-Newtonian N-body simulations in \cref{chap:GNQ}.

In all these cases we have seen that taking into account non-linearities yields observable effects that will
be measured with high precision in future galaxy surveys. Using only linear theory and limiting the 
analysis to linear scales, not only worsens the forecasted constraints by more than one order of magnitude (see 
\cref{chap:MG-forecasts}), but can also bias the result (see \cref{chap:Fitting-CDE}).
Even more dramatically, for certain models of Modified Gravity, involving strong ``fifth-forces``, 
the predictions of the model cannot be calculated properly using linear theory, and one is forced to compute
all observables, even the background quantities, with the help of specialized N-body simulations (see \cref{chap:GNQ}).

In \cref{chap:Statistics} we detail the Fisher matrix method and the code we created to forecast the
constraining power of future surveys, using Galaxy Clustering and Weak Lensing observables. We concentrated on the missions: 
Euclid, SKA1, SKA2 and DESI. All of them will be started in the next 2 to 10 years.
We also explained how we introduce non-linearities into the Fisher matrix formalism and how we deal with the unknown 
estimation of the power spectrum and the involved sources of noise and errors.

The field of non-linear structure formation and its application to the analysis of cosmological observations
is a field which is advancing very rapidly, due to the urgent necessity of understanding this problem in order
to gain as much information as possible from future data.

In the near future we would still need to explore several open questions in this field.
For example, how degenerate are the Modified Gravity predictions at non-linear scales, with other
effects like the neutrino mass, baryonic feedback and the unknown properties of bias and primordial non-Gaussianities.
Especially the effect of baryonic physics at small scales, is of great concern, since it can affect and wash away
most cosmological information above a certain wavenumber. This is an open issue that has to be resolved in such a way, that allows 
future observational cosmologists to discard as little information as possible from small scales.

Another issue we need to solve is how to parameterize optimally the effects of Modified Gravity models. As we have seen 
in \cref{chap:MG-forecasts}, the most parameterization independent way of doing this, is to \emph{pixelize} the evolution
of $\mu(a)$ and $\eta(a)$ in redshift bins. However, it is not clear how many bins need to be used, which
priors can be imposed on these binned parameters and if in general, parameterizing $\mu$ and $\eta$ as we have done in 
\cref{chap:MG-forecasts}, is still a valid approach once non-linear corrections are taken consistently into account.

All this can only be investigated once a semi-analytic method (like the resummation method of \cref{chap:nonlinear}) 
for computing non-linearities in Modified Gravity theories is mature enough to yield consistent results for 
a large range of models and parameters. Exploring
the model and parameter space will not be feasible in the near future by computing for each model a separate N-body simulation.

In terms of Fisher forecasts, we have shown at the end of \cref{chap:Statistics} how we can go beyond the Gaussian approximation for the likelihood.
However, for a proper analysis of non-linear structure formation, we still would need to take into account 
non-diagonal covariance matrices, cross-correlations among Galaxy Clustering and Weak Lensing and small scale effects
modifying our formulas for the Baryon Acoustic Oscillations and Redshift Space Distortions. This will be the subject of future
work on the \textsc{FisherTools} code.

In this thesis we have dealt almost exclusively with the non-linear matter power spectrum. But we know that at highly non-linear scales,
this statistical measure cannot give us the full picture. The cosmic web, consisting of voids, sheets and filaments, is not
well described by the two-point correlation function. Going to the three-point correlation function (called the bispectrum in Fourier space)
can yield already some extra information, although its calculation is quite demanding. 
However, this will not be enough, and for future data, we will need to find
some other statistical measures that can give us clear information of what is happening at the smallest scales.
Possible options could be Minkowski functionals, position dependent power spectra, large deviation statistics and 
massive galaxy clusters, just for naming a few.

Definitely, the next decade of the precision era of cosmology, will be an era of rapid technological advances,
impressive developments in theory and statistical tools and many surprising discoveries.










